{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import v2 as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'Data')\n",
    "images_dir_root = os.path.join(path_base,'data_sorted','frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, p13, p14, p15, p16 = ([] for i in range(16))\n",
    "for dir in os.listdir(images_dir_root):\n",
    "    if 'p1_' in dir:\n",
    "        p1.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p2' in dir:\n",
    "        p2.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p3' in dir:\n",
    "        p3.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p4' in dir:\n",
    "        p4.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p5' in dir:\n",
    "        p5.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p6' in dir:\n",
    "        p6.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p7' in dir:\n",
    "        p7.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p8' in dir:\n",
    "        p8.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p9' in dir:\n",
    "        p9.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p10' in dir:\n",
    "        p10.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p11' in dir:\n",
    "        p11.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p12' in dir:\n",
    "        p12.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p13' in dir:\n",
    "        p13.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p14' in dir:\n",
    "        p14.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p15' in dir:\n",
    "        p15.append(os.path.join(images_dir_root, dir))\n",
    "    elif 'p16' in dir:\n",
    "        p16.append(os.path.join(images_dir_root, dir))\n",
    "video_dirs = [p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, p13, p14, p15, p16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_path = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'cleaned.csv')\n",
    "df = pd.read_csv(report_path)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "analyzed_path = os.path.join(path_base, 'analyzed_imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\admin\\\\Documents\\\\Arthroskopie\\\\Data\\\\data_sorted\\\\frames\\\\p1_v1\\\\frame_001337.PNG'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = video_dirs[0]\n",
    "frames = os.listdir(videos[0])\n",
    "os.path.join(videos[0], frames[1337])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train, h_flip, v_flip):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(h_flip))\n",
    "        transforms.append(T.RandomVerticalFlip(v_flip))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(video, id, model, device):\n",
    "    image = read_image(os.path.join(video, id))\n",
    "    eval_transform = get_transform(train=False, h_flip=0, v_flip=0)\n",
    "    with torch.no_grad():\n",
    "        y = eval_transform(image)\n",
    "        y = y[:3, ...].to(device)\n",
    "        predictions = model([y, ])\n",
    "        pred = predictions[0]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frames(patient, frames_to_accumalate, model, device):\n",
    "    analyzed_images = []\n",
    "    videos = video_dirs[patient]\n",
    "    for x in videos:\n",
    "        frames = os.listdir(x)\n",
    "        counter = 0\n",
    "        while counter < len(frames):\n",
    "            one_hot = torch.zeros(32)\n",
    "            scores = torch.zeros(32)\n",
    "            for i in range(frames_to_accumalate):\n",
    "                if counter+i < len(frames):\n",
    "                    pred = analyze_image(x, frames[(counter+i)], model, device)\n",
    "                    for z in range(len(pred[\"labels\"])):\n",
    "                        cat = pred[\"labels\"][z].item()-1\n",
    "                        score = pred[\"scores\"][z].item()\n",
    "                        if score >= 0.75:\n",
    "                            if one_hot[cat] == 0:\n",
    "                                one_hot[cat] = 1\n",
    "                                scores[cat] = score\n",
    "                            else:\n",
    "                                if scores[cat] < score:\n",
    "                                    scores[cat] = score\n",
    "                else:\n",
    "                    break                    \n",
    "        \n",
    "            fin_img=torch.cat([torch.zeros(15), one_hot, scores])\n",
    "            analyzed_images.append(fin_img)\n",
    "            counter += frames_to_accumalate\n",
    "            \n",
    "        print(\"Finished: \", x)\n",
    "    return analyzed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import  load\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "with open(os.path.dirname(os.getcwd()) + \"\\\\Object_Detection\\\\dataloaders\\\\names_to_annotation.pkl\", \"rb\") as input_file:\n",
    "   names_to_annotation = load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_path = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'cleaned.csv')\n",
    "df = pd.read_csv(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ICD-Code'][0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_dict = {}\n",
    "counter = 0\n",
    "\n",
    "for row in df['ICD-Code'][0:16]:\n",
    "    try:\n",
    "        for code in row.split(','):  \n",
    "            cleaned_code = code.strip()\n",
    "            if cleaned_code not in icd_dict.keys():\n",
    "                icd_dict[cleaned_code] = counter\n",
    "                counter +=1\n",
    "    except:\n",
    "        print('Skipped: ' , row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icpm_dict = {}\n",
    "counter = 0\n",
    "\n",
    "for row in df['ICPM-Code'][0:16]:\n",
    "    try:\n",
    "        for code in row.split(','):  \n",
    "            cleaned_code = code.strip()\n",
    "            if cleaned_code not in icpm_dict.keys():\n",
    "                icpm_dict[cleaned_code] = counter\n",
    "                counter +=1\n",
    "    except:\n",
    "        print('Skipped: ' , row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icpm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_codes(icd, icpm):\n",
    "    icd_codes = torch.zeros(7)\n",
    "    icpm_codes = torch.zeros(8)\n",
    "\n",
    "    try:\n",
    "        icd_list = icd.split(',')\n",
    "        for code in icd_list:\n",
    "            cleaned_code = code.strip()\n",
    "            pos = icd_dict[cleaned_code]\n",
    "            icd_codes[pos] = 1\n",
    "\n",
    "        icpm_list = icpm.split(',')\n",
    "        for code in icpm_list:\n",
    "            cleaned_code = code.strip()\n",
    "            pos = icpm_dict[cleaned_code]\n",
    "            icpm_codes[pos] = 1\n",
    "    except:\n",
    "        print('Skipped NaN')\n",
    "    \n",
    "    return torch.cat([icd_codes, icpm_codes, torch.zeros(82)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import  dump\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = torch.load(os.path.dirname(os.getcwd()) + \"\\\\Object_Detection\\\\Models\\\\model_whole_no_empty.pt\", weights_only=False)\n",
    "model.to(device)\n",
    "\n",
    "for a in range(len(video_dirs)):\n",
    "    \n",
    "    series = df.loc[a]\n",
    "    icd_icpm = tokenize_codes(series.iloc[2], series.iloc[4])\n",
    "    \n",
    "    frames = generate_frames(a, 30, model, device)\n",
    "\n",
    "    data = {'Ablauf':series.iloc[1],'icd_icpm': icd_icpm, 'frames': frames}\n",
    "    \n",
    "    file_name = \"p{}.pkl\".format(a+1)\n",
    "    print(file_name)\n",
    "    with open(os.path.join(analyzed_path, file_name), 'wb') as f:\n",
    "        dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import  load\n",
    "\n",
    "test_path = os.path.join(path_base, 'analyzed_imgs')\n",
    "dir = os.listdir(test_path)\n",
    "\n",
    "for file in dir:\n",
    "   with open(os.path.join(test_path, file), \"rb\") as input_file:\n",
    "      input = load(input_file)\n",
    "      list = input['frames']\n",
    "   print(f'{file}: {len(list)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Athroskopie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
